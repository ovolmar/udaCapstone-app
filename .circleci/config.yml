version: 2.1
commands:
  destroy-eks-env:
    description: Destroy EKS CF Stack
    parameters:
      workflowid:
        type: string
        default: ${ CIRCLE_WORKFLOW_ID:0:7 }
    steps:
      - run:
          name: delete eks cluster
          when: on_fail
          command: |
            curl --silent --location https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz | tar -xz -C /tmp
            sudo mv /tmp/eksctl /usr/local/bin
            eksctl delete cluster -f infrastructure/k8s-cluster.yml
  cluster-status:
    description: Get cluster status 
    parameters:
      workflowid:
        type: string
        default: ${CIRCLE_WORKFLOW_ID:0:7}
    steps:
      - run:
          name: cluster status
          command: |
            /usr/local/bin/aws eks describe-cluster \
            --region {AWS_DEFAULT_REGION}  \
            --name udacapstone-k8s-cluster \
            --query "cluster.status"

# Adding a build command here with a revert-migrations
#
#--------------------------------------------------------------------------------------------------------------------------          
jobs:
  lint:
    docker:
      - image: python:3.7.3-stretch
    steps:
      - checkout 
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-
      - run:
          name: "linting"
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
            # Install hadolint
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 &&\
            chmod +x /bin/hadolint
            make lint
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}

  buildcontainer:
    docker:
      # Use the same Docker base as the project
      - image: cimg/go:1.17
        auth:
          username: $DOCKER_LOGIN
          password: $DOCKER_PASSWORD
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-
      - setup_remote_docker:
          version: 20.10.14
          docker_layer_caching: true
      - run:
          name: "Building Docker Container and upload it"
          command: |
            touch ".env"
            echo DOCKER_LOGIN=${DOCKER_LOGIN} >> ".env"
            echo DOCKER_PASSWORD=${DOCKER_PASSWORD}  >> ".env"
            echo IMAGE_NAME=${IMAGE_NAME} >> ".env"
            source ".env"
            docker build -t ${IMAGE_NAME} .
            docker tag $IMAGE_NAME ovolmar/${IMAGE_NAME}:latest
            docker login -u ${DOCKER_LOGIN} -p ${DOCKER_PASSWORD}
            docker push ovolmar/${IMAGE_NAME}
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}

  deploycluster:
    docker:
      - image: cimg/aws:2022.06
    working_directory: ~/tmp
    steps:
      - checkout
      - run:
          name: Loading Latest AWSCLI
          command: |
            if [ -f /usr/local/bin/aws ]; then
              echo "AWS is loaded moving on"
            else 
              curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
              unzip awscliv2.zip
              sudo ./aws/install
            fi 

      - run:
          name: Install kubectl and eksctl
          command: |
            aws --version
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
            curl --silent --location https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_Linux_amd64.tar.gz | tar -xz -C /tmp
            sudo mv /tmp/eksctl /usr/local/bin

      - run: 
          name: Build EKS cluster
          command: |
            #eksctl create cluster -f infrastructure/k8s-cluster.yml
            /usr/local/bin/aws eks describe-cluster --region ${AWS_DEFAULT_REGION} --name udacapstone-k8s-cluster --query "cluster.status" 2> eks_status
            if [ $? != 0 ]; then  eksctl create cluster -f infrastructure/k8s-cluster.yml ; else exit 0 ; fi
  pod-launcher:
    # docker:
    #   - image: circleci/python
    # steps:
    #   - checkout
    #   - restore_cache:
    #       keys:
    #         - ./venv
    #       key: v1-dependencies-{{ checksum "requirements.txt" }}
    #   - run:
    #       name: running ansible
    #       command: |
    #         pip install ansible 
    #         ansible-playbook ansible/cluster.yml
    docker:
      - image: cimg/aws:2022.06
    steps:
      - checkout 
      - run:
          name: launching pods
          command: |
            /usr/local/bin/aws eks update-kubeconfig --name udacapstone-k8s-cluster --region ${AWS_DEFAULT_REGION} 
            kubectl apply -f infrastructure/bluepod.yml
            kubectl apply -f infrastructure/blue-services.yml
            kubectl apply -f infrastructure/ingress.yml
            kubectl expose deployment flask-capstone --type=ClusterIP --name=service-cluser-ip
            sleep 40
            kubectl get svc

workflows: 
  default:
    jobs:
      - buildcontainer
      - lint
      - deploycluster:
          requires: [buildcontainer]
      - pod-launcher:
          requires: [deploycluster]
      